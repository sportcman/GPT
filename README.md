# GPT Разработка с PyQt6

Этот проект включает разработку и обучение моделей GPT для различных типов данных. Все скрипты снабжены графическим интерфейсом, созданным с использованием PyQt6, что позволяет удобно настраивать параметры и управлять процессом обучения.

## Основные функции

- **Создание токенизаторов**: Поддержка различных подходов к созданию токенизаторов для текстовых данных.
- **Обучение моделей GPT**: Возможность настраивать параметры модели для оптимального обучения под конкретные данные.
- **Графический интерфейс (PyQt6)**: Все скрипты имеют GUI, который позволяет:
  - Настраивать параметры модели (количество слоев, размер скрытого слоя, количество эпох и пр.)
  - Выбирать файлы для обучения, тестирования, а также местоположения для сохранения модели.
  - Визуализировать процесс обучения (количество эпох, количество батчей, потери и прогресс обучения).

## Установка

Для запуска проекта необходимо установить следующие зависимости:
pip install torch transformers PyQt6

## Описание скрипта для создания токенизатора.##

Этот Python-скрипт с графическим интерфейсом (GUI) на PyQt6 позволяет пользователю создавать собственные токенизаторы на базе модели BPE (Byte Pair Encoding) с помощью библиотеки tokenizers. Пользователь может ввести собственные токены, а также указать директорию для сохранения сгенерированных файлов токенизатора. Основные файлы, которые создаются после обучения токенизатора: tokenizer.json, vocab.json, merges.txt, special_tokens_map.json, и tokenizer_config.json.

## Принцип работы
Инициализация интерфейса:

Основной класс TokenizerApp создает графический интерфейс с элементами управления:
Текстовое поле для ввода токенов (по умолчанию предоставлены специальные токены и стандартные символы).
Поле и кнопка для выбора папки, куда будут сохранены файлы токенизатора.
Кнопка для запуска процесса создания токенизатора.
Строка состояния для отображения информации о текущем процессе.
Пользовательский ввод:

Пользователь может вручную ввести или отредактировать токены, которые будут использоваться в токенизаторе.
Папка для сохранения выходных файлов выбирается с помощью стандартного файлового диалога.
Создание токенизатора:

После нажатия на кнопку "Создать токенизатор" приложение получает введенные токены и директорию для сохранения файлов.
Далее токенизатор настраивается с использованием модели BPE из библиотеки tokenizers.
Настраивается тренер (BpeTrainer), который определяет параметры обучения, такие как размер словаря (в данном случае 99) и специальные токены.
Токенизатор тренируется на введенных данных, и после завершения процесса создаются несколько выходных файлов:
tokenizer.json – основной файл токенизатора, содержащий параметры модели и словарь.
vocab.json – файл с картой токенов.
merges.txt – файл с информацией о парах символов для слияния в BPE.
special_tokens_map.json – файл, содержащий карту специальных токенов.
tokenizer_config.json – файл с конфигурацией токенизатора.
Статус и сообщения об ошибках:

Если пользователь не выбрал папку для сохранения или не ввел токены, приложение отображает соответствующие сообщения об ошибках в статусной строке.
При успешном создании токенизатора пользователю выводится уведомление о завершении.
Таким образом, этот скрипт предоставляет удобный способ для создания и настройки токенизаторов с графическим интерфейсом.


## Описание проекта создания модели.
Этот скрипт на Python предоставляет графический интерфейс (GUI) для настройки параметров и создания модели на базе архитектуры GPT (Generative Pre-trained Transformer) с использованием библиотеки transformers. Пользователи могут задать конфигурацию модели через интерфейс, выбрать токенизатор и задать путь для сохранения обученной модели.

## Основные компоненты:
## Многопоточное создание модели:

Используется класс ModelThread, который запускается в отдельном потоке для предотвращения зависания интерфейса во время создания модели. В этом классе осуществляется загрузка токенизатора, создание конфигурации модели и сохранение обученной модели и токенизатора.
Поток отправляет сигналы для обновления текстового поля с информацией о процессе, прогресса создания модели и сигнала о завершении.
Интерфейс пользователя:

## Приложение содержит вкладки:
Создание модели: отображает текстовую информацию о процессе и прогресс создания модели.
Настройки: позволяет пользователю вводить параметры для настройки модели, такие как путь к токенизатору, путь для сохранения модели, количество слоев, количество голов внимания, размер эмбеддингов и другие.
Вкладка "Создание модели" отображает прогресс создания модели с помощью прогресс-бара и предоставляет кнопку выхода после завершения процесса.
Вкладка "Настройки" содержит форму для ввода параметров конфигурации модели, таких как размер модели, количество слоев и голов внимания.
Принцип работы:
Настройка параметров модели:

## Пользователь вводит путь к токенизатору и путь для сохранения модели, а также настраивает параметры модели, такие как количество слоев, голов внимания, скрытые размеры и т.д.
Создание модели:

После нажатия на кнопку "Начать создание модели", создается поток, который запускает процесс создания модели. Процесс включает:
Загрузку предварительно созданного токенизатора.
Создание конфигурации GPT-модели с заданными параметрами.
Инициализацию модели и её сохранение вместе с токенизатором в указанный пользователем путь.
Отслеживание процесса:

Прогресс создания модели и сохранения отображается в текстовом поле и прогресс-баре на вкладке "Создание модели". В случае успешного завершения кнопка "Выход" становится активной.
Зависимости:
Python 3.x
PyQt6 (для создания GUI)
transformers (для работы с моделью GPT)
Запуск:
Для запуска проекта, выполните следующие шаги:

Установите необходимые библиотеки:


pip install PyQt6 transformers

Примечание:
Скрипт предназначен для использования предварительно обученного токенизатора, который должен быть загружен из указанного пользователем пути.
Модель и токенизатор сохраняются в формате, совместимом с библиотекой transformers.

## Описание проекта обучения модели.
Этот проект предоставляет графический интерфейс для управления процессом обучения моделей на базе GPT с использованием PyTorch и библиотеки Transformers. Основные функции интерфейса включают:

## Загрузка модели и текстового датасета для обучения.
Настройка параметров обучения, таких как размер батча, количество эпох, шаги накопления градиентов, размер блока и перекрытие фрагментов.
Запуск и остановка процесса обучения.
Отображение прогресса обучения и логов (включая потери на каждой партии и завершение эпохи).
Сохранение обученной модели и токенизатора.
Основные компоненты
Класс CustomTextDataset:

Предназначен для создания датасета из текстового файла.
Использует токенизатор для преобразования текста в числовые последовательности.
Позволяет задавать размер блока токенов и перекрытие между блоками, что помогает при обучении модели на больших объемах данных.
Класс TrainingWorker (наследник QThread):

В отдельном потоке выполняет обучение модели, чтобы интерфейс оставался отзывчивым.
Поддерживает настройку таких параметров, как размер батча, количество эпох, перекрытие фрагментов, накопление градиентов и другие.
Обновляет прогресс-бар и выводит лог обучения в реальном времени.
Реализует возможность остановки обучения пользователем с последующим сохранением модели и токенизатора.
Класс MainWindow:

Графический интерфейс приложения, написанный с использованием PyQt6.
Позволяет пользователю выбрать модель, датасет и настроить параметры обучения через интерактивные элементы (кнопки, поля ввода, флажки).
Отображает прогресс обучения и логи, позволяет запускать и останавливать обучение.
Основные шаги работы программы
Выбор модели и датасета:

Пользователь выбирает директорию с предобученной моделью GPT и текстовый файл для обучения.
Настройка параметров:

Можно настроить такие параметры, как размер батча, количество эпох, шаги накопления градиентов, размер блока токенов и включение/выключение перекрытия фрагментов.
Запуск обучения:

По нажатию кнопки «Начать обучение» запускается обучение модели в отдельном потоке, чтобы интерфейс оставался отзывчивым. В процессе обучения выводится информация о прогрессе и потерях.
Остановка обучения:

Пользователь может остановить обучение, при этом текущая модель и токенизатор будут сохранены.
Сохранение модели:

После завершения обучения или остановки пользователем, модель и токенизатор сохраняются в директорию, выбранную для модели.
Особенности
Использование потока для обучения (через QThread), чтобы не блокировать основной интерфейс.
Возможность настройки перекрытия фрагментов текста для более эффективного обучения на небольших батчах.
Сохранение обученной модели и токенизатора для последующего использования.
Установка и запуск
Установите необходимые библиотеки:

pip install torch transformers PyQt6

## Пример использования
Выберите директорию с предобученной моделью GPT.
Выберите текстовый файл для обучения.
Настройте параметры обучения (batch size, количество эпох и другие).
Нажмите кнопку «Начать обучение».
Следите за прогрессом и логами в интерфейсе.
После завершения обучения модель будет сохранена в выбранную директорию.
Требования
Python 3.8+
PyTorch
Transformers от Hugging Face
PyQt6

## Проверка модели описание проекта.
Этот проект представляет собой графическое приложение на Python для генерации текста с использованием предобученной модели GPT. Программа позволяет пользователю вводить текстовый запрос, выбирать модель для генерации, а также настраивать параметры генерации, такие как температура, длина генерируемого текста и количество вариантов. Интерфейс приложения построен на основе библиотеки PyQt6 и предоставляет удобные элементы управления для взаимодействия с моделью.

## Основные компоненты
GPTGenerator:
Этот класс отвечает за загрузку модели GPT и генерацию текста на основе входного текста и заданных параметров. Он использует библиотеку transformers для работы с моделью и токенизатором. После генерации текст форматируется с помощью библиотеки pygments для подсветки синтаксиса.

__init__(model_path): Загружает модель и токенизатор из указанного пути.
generate_text(input_text, temperature_value, length_value, num_results, no_repeat_ngram_size): Генерирует текст на основе входного текста и параметров генерации, таких как температура, длина и количество вариантов.
GPTApp:
Это главное окно приложения, которое управляет пользовательским интерфейсом. Оно включает две вкладки: одну для генерации текста, другую для управления настройками модели.

initUI(): Инициализирует интерфейс с вкладками и элементами управления.
createGenerateTab(): Создает вкладку для генерации текста с возможностью ввода запроса, выбора модели и настройки параметров.
createSettingsTab(): Создает вкладку настроек, где пользователь может добавлять, удалять и просматривать доступные модели.
generateText(): Обрабатывает нажатие кнопки генерации текста и вызывает метод генерации.
updateTemperatureDisplay(value): Обновляет значение температуры в зависимости от положения ползунка.
addModel(): Позволяет добавлять новые модели через диалог выбора директории.
removeModel(): Удаляет выбранную модель из списка.
clearSettings(): Очищает все настройки и загруженные модели.
loadSettings(): Загружает сохраненные модели и настройки из файла settings.json.
saveSettings(): Сохраняет текущие настройки и пути к моделям в файл settings.json.
Принцип работы
Загрузка модели: При старте приложения загружаются пути к сохраненным моделям из файла настроек. Пользователь может добавить новую модель, выбрав директорию, где она находится.

Настройка параметров: Пользователь может настроить параметры генерации, такие как температура (контролирует случайность генерации), максимальная длина генерируемого текста и количество вариантов.

Генерация текста: После ввода текста и выбора модели, программа вызывает метод генерации текста, который использует токенизатор и модель GPT для создания нового текста. Генерированный текст отображается в формате с подсветкой синтаксиса.

Сохранение настроек: Все изменения, сделанные пользователем (выбранные модели, параметры), сохраняются в файл settings.json, чтобы они сохранялись при следующем запуске программы.

## Как использовать

Введите текстовый запрос в поле "Введите вопрос" на вкладке "Генерация текста".
Выберите модель для генерации текста.
Настройте температуру, длину текста и количество вариантов.
Нажмите кнопку "Сгенерировать ответ" и дождитесь результата.
Зависимости
## Для работы программы необходимы следующие библиотеки:

Python 3.9+
PyQt6
torch
transformers
pygments
